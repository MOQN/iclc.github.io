<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no" />

	<title>ICLC 2024: GravField: Inter-bodily Live-coding Performance &amp; Workshop</title>

	<!-- Fonts -->
	<link rel="preconnect" href="https://fonts.googleapis.com">

	<script src="https://use.fontawesome.com/releases/v6.1.0/js/all.js" crossorigin="anonymous"></script>

	<!-- CSS sheets -->
	<link href="../css/style.css" rel="stylesheet" />
	<link href="../css/style-customized.css" rel="stylesheet" />

	<!-- Bootstrap -->
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.min.js"></script>
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>

	<!-- Script that generates HTML elements on the main page. -->
	<script src="../js/script-elements.js"></script>
	<script defer src="../js/script.js"></script>
</head>

<body id="page-top">
	<script>
		// HEADER
		navigationBar();

		// BACKGROUND IMAGE
		//backgroundImage('./assets/img/algo6.jpg');
		// note: I am not sure if we need a backgroud image for these pages
		// we can have a random shuffling of images in the background?
		// or generate a random sketch using p5.js?

		// MAIN
		mainContainer(); // required for the section() function to be appended to the main container

		// SPACER
		spacer("main-container", "15vh");

		// BACK BUTTON
		html('main-container',
			`<a href="javascript:history.back()" class="back-button">
				Back
			</a>`
		);

		// ABOUT
		section('act', 'main-section');
		horizontalLine('act');
		heading('act', 'GravField: Inter-bodily Live-coding Performance &amp; Workshop', 1);
		heading('act', '<a href="../persons/botao-a-hu.html">Botao A Hu</a>, <a href="../persons/yuemin-huang.html">Yuemin Huang</a>, <a href="../persons/mingze-chai.html">Mingze Chai</a>, <a href="../persons/yilan-tao.html">Yilan Tao</a>, <a href="../persons/aaron-hu.html">Aaron Hu</a>', 4);
		html('act',
			`<p>”Gravitational Field” (GravField) is an experimental and participatory live performance set in a co-located mixed reality environment. Participants wearing AR headsets are invited to join and collectively create real-time music through their collaborative body movements, guided by the programmed affordance settings from live-coders. This innovative experiment harnesses intercorporeal signals derived from participants’ body movements, including factors like distance, area formation, relative height differences, and head motion synchronization. Live-coders dynamically map these signals into metaphorical audiovisual patterns in augmented reality, providing participants with cues about the relationships between players. The live-coded patterns shape and influence participants’ improvisation of body movements, while adjustments in live coding dynamically alter how these movements generate sound, influencing the overall improvisational experience. In addition, spectators outside the live performance area can enjoy the mixed reality performance through projection screens and TVs, enhancing audience engagement. GravField aims to explore the vast potential of intercorporeal signals, creating a communicative, playful, and co-creative space where players’ interconnected bodies become the instruments of expression.</p>`);
		html('act', '<div class="proceedings"><a href="https://zenodo.org/records/12776490" target="_blank">Entry in Proceedings</a></div>');
		html('act', '<div class="documentation"></div>');

		spacer("act", "5rem");

		// FOOTER
		//socials();
		//footer();
	</script>
</body>

</html>